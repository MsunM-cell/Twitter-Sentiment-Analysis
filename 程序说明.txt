三个py文件，一个用于小数据集上，一个用于大数据集上，简单投票.py是将大数据集上生成的20个表格筛选出最高的值，作为预测结果

main（大数据集）程序思路（小数据集上同理）：
1.首选读取数据Twitter_sentiment_selfdrive_DFE.csv，去掉无关的列，只留下sentiment和txet列，由于大数据集上多了一个分类not_relevant
因此去除这个类别的样本，然后将sentiment列的格式转为int64，防止格式出错，调用value_counts()函数，统计各个类别的样本数。

2.把训练集和测试集合并在一起，这样方便做数据清理，首先去除含@user的字段，然后将文本转为小写，去除url链接，去除标点符号和特殊字符，然后
进行缩写扩展，比如把won't转为 will not等等，接着移除短单词，然后去除停用词（要保留nor not 和no等含有情绪倾向的词），最后保存清洗完毕后
的数据combi1.csv。

3.调用tfidf提取训练集和测试集特征，设置停用词为英文，由于类别分布不平衡，因此采用SMOTE对训练集进行上采样，使得类别分布平衡，然后输出各个类别个数
可以与之前没有上采样的类别个数比较。

4.使用train_test_split从训练集中划分验证集，验证集的比列为0.1，使用StratifiedKFold进行10折交叉验证。

5.构建SVM模型，使用10折交叉验证生出10个不同的模型，然后分别在验证集上检验结果，输出准确率，最后在测试集上预测，保存预测结果predict_by_model_SVM_{i+1}.csv

6.同上，构建随机森林模型，使用10折交叉验证生出10个不同的模型，然后分别在验证集上检验结果，输出准确率，最后在测试集上预测，保存预测结果predict_by_model_RF_{i+1}.csv



简单投票.py程序思路
1.读取10个RF的预测表格和10个SVM的预测表格，然后使用pd.merge进行左右拼接
2.调用collection库中的Counter函数，选出每个样本预测频率的最大值作为最终预测结果
3.创建一个DataFrame对象，保存text.csv中的id和text列，然后添加一列sentimen，里面的内容就是每个样本的预测标签，最后重命名为final_submit.csv

